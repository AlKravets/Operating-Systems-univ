# Лабораторные работы по предмету "Операционные системы"

- [Лабораторные работы по предмету "Операционные системы"](#лабораторные-работы-по-предмету-операционные-системы)
  - [Лабораторная №1 "Поставщик - Обработчик - Потребитель"](#лабораторная-1-поставщик---обработчик---потребитель)
    - [Реализация Python](#реализация-python)
      - [(Producer -> Handler -> Consumer) с использованием treading.Condition](#producer---handler---consumer-с-использованием-treadingcondition)
      - [(Producer -> Handler -> Consumer) с использованием treading.Lock](#producer---handler---consumer-с-использованием-treadinglock)
    - [Реализация C++](#реализация-c)
    - [Реализация C](#реализация-c-1)
  - [Лабораторная работа №2](#лабораторная-работа-2)
    - [Первый вариант реализации](#первый-вариант-реализации)
      - [Клиентская часть](#клиентская-часть)
      - [Серверная часть](#серверная-часть)
      - [Подстановка функций *f*, *g*](#подстановка-функций-f-g)
  - [Лабораторная №3 "Взаимодействие потоков, критический сегмент"](#лабораторная-3-взаимодействие-потоков-критический-сегмент)
    - [Код программы](#код-программы)
    - [Настройка визуализации результатов](#настройка-визуализации-результатов)
    - [Визуализация результатов](#визуализация-результатов)

## Лабораторная №1 "Поставщик - Обработчик - Потребитель"

У меня был вариант №4. Было дано такое условие

Реализуйте задачу по обработке информации через 1 буфер обмена, если:
- первый поток (поставщик, producer) заполняет буфер обмена данными;
- второй поток (обработчик, handler) перекодирует большие буквы текста в маленькие;
- третий поток (потребитель, consumer) записывает обработанные данные в выходной файл.

Корректно реализованная задача не приведет к изменению текста в выходном файле (по длине, по значению).

Я постарался реализовать программу на 3 разных языках
- [python source](lab1/python/ProducerHandlerConsumer.py)
- [C++ source](lab1/С++/Producer%20Handler%20Consumer.cpp)
- [C# source](lab1/C%20sharp/main.cs)

### Реализация Python

Код лежит [тут](lab1/python/ProducerHandlerConsumer.py). Я реализовал 2 варианта:

#### (Producer -> Handler -> Consumer) с использованием [treading.Condition](https://docs.python.org/3/library/threading.html#condition-objects)

Это реализовано в классе `PHC_With_Threading_Condition`. У каждого потока есть свой `threading.Condition`, и после своей итерации цикла каждый поток зависает в ожидании, пока другой поток не разбудит его.

Для создания объекта класса нужно указать:
- `producer` -  генератор, что создает данные
- `handler` - функция, что обрабатывает строки
- `consumer` - функция, что сохраняет данные
- `max_size_buffer`- ограничение для буфера. После заполнения буфера поток Producer войдет в ожидание и передаст управление потоку Handler. После работы Consumer, Producer вновь начнет работу.

#### (Producer -> Handler -> Consumer) с использованием [treading.Lock](https://docs.python.org/3/library/threading.html#lock-objects)

Это реализовано в классе `PHC_With_Three_Locks`. У каждого потока есть свой Lock. Из-за этого каждый поток блокирует сам себя после итерации цикла. Перед блокировкой поток освобождает нужный заблокированный поток, что должен продолжить работу.

Класс принимает такие же параметры, что и прошлый.

### Реализация C++

Код лежит [тут](lab1/С++/Producer%20Handler%20Consumer.cpp).

Я реализовал идею с 3 блокировками. Тут использованы mutex-ы для каждого потока. Из-за них потоки блокируют сами себя и ожидают, пока другие потоки их не освободят.

### Реализация C#

Код лежит [тут](lab1/C%20sharp/main.cs).

И вновь, тут похожая идея с блокировками. Тут использованы `AutoResetEvent` для каждого потока. После итерации цикла потока, он блокирует сам себя, пока другой поток не даст сигнал на изменение состояния `AutoResetEvent`.

***

## Лабораторная работа №2

Программы (процессы, потоки -- согласно варианту задачи), что реализуют функции *f(x)* и *g(x)*, занимаются только вычислением значений над входным аргументом, они не обрабатывают никаких запросов (в том числе про завершение вычислений) ы не взаимодействуют с другими процессами и потоками никакими иными способами, кроме вызовов вычислений *f(x)* и *g(x)* (то есть запуска функции на вычисления) и возвращение результатов (когда вычисления завершены)

**Обратите внимание**, что функции *f*, *g* -- могут быть частично определены (то есть *зацикливаться* и никогда не возвращать результат). Нужно корректно обработать такую ситуацию и спросить пользователя: "продолжить вычисления, закончить или продолжить, не спрашивая более" например, каждые 10 секунд.

**Взаимодействие процессов. Параллелизм. Обмен сообщениями через порт.** Вычислить _f(x) || g(x)_ (логическое **или**) используя 2 вспомогательных процесса: один вычисляет *f(x)*, второй -- *g(x)*. Основная программа выполнят ввод-вывод и операцию ||. Использовать обмен сообщениями между процессами через порт (Socket). Реализовать вариант блокирующих операций обмена сообщениями, то есть с ожиданием обработки сообщения и ответа на сообщение (и *зависанием* процесса на это время). Функции *f(x)* и *g(x)* *ничего не знают друг о друге* и не могут коммуницировать между собой.

### Первый вариант реализации

- [код программы](lab2/variant1.py)

Основная проблема программы заключается в необходимости использовать сокеты. Программу можно разделить на серверную и клиентскую части. 


#### Клиентская часть

В условии лабораторной указано требование отделить вычисления от передачи данных. Поэтому клиент, который запускается в отдельном процессе, самостоятельно порождает процесс в котором считается функция (*f* или *g*). После получения результата вычислений результат передается процессу клиенту при помощи Pipe. Сам клиент отправляет результат серверу либо реагирует на команды, что прислал сервер.

Как можно увидеть в коде программы

<!-- Cspell:disable -->
```py
parent_connect , child_connect = mp.Pipe() # создаем Pipe для синхронизации процессов
p = mp.Process(target=decor_add_pipe(func), args=(f_arg, child_connect))
```
<!-- Cspell:enable -->

Функции *f*, *g* не изменяются, для того, чтобы перенаправить их вывод в **Pipe** используется **декоратор**

<!-- Cspell:disable -->
```py
def decor_add_pipe(function_to_decorate):
    def wrapper(f_arg, pipe_connect):
        pipe_connect.send(function_to_decorate(f_arg))
    return wrapper
```
<!-- Cspell:enable -->

Клиенту могут прийти команды, что он должен обработать, но он еще должен следить за выполнением вычислений и отправкой результата. Эту проблему я решил установкой маленького времени ожидания (*timeout*) на соединение:

<!-- Cspell:disable -->
```py
s.settimeout(0.1)
# ... #

while p.is_alive() and not kill_flag:
  try:
      command = int(s.recv(1024))
      # ... #
  except socket.timeout:
      pass
```
<!-- Cspell:enable -->

По сути мы стараемся получить команду от сервера, но через *timeout* времени происходит выброс исключения, которое мы игнорируем. Это продолжается пока происходят вычисления функции *f* или *g*.

Команды, которая может прийти клиенту (это аналог *enum* в языке C++): 

<!-- Cspell:disable -->
```py
class Status(IntFlag):
    Pause = 0
    Cont = 1
    End = 2
    Cont_no_Ques = 3 # продолжить без вопросов
```
<!-- Cspell:enable -->

Когда приходит команда, то клиент отправляет соответствующий [сигнал](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%B3%D0%BD%D0%B0%D0%BB_(Unix)) процессу, который производит вычисления (`p.kill` отправляет сигнал `SIGKILL`)

<!-- Cspell:disable -->
```py
            if command == Status.Pause:
                os.kill(p.pid, signal.SIGTSTP) 
            elif command == Status.Cont:
                os.kill(p.pid, signal.SIGCONT)
            elif command == Status.End:
                p.kill()
                
                kill_flag = True
                child_connect.close()
                parent_connect.close()
                del child_connect
                del parent_connect
            else:
                pass   
```
<!-- Cspell:enable -->

После всего этого, **если был получен результат вычислений**, то он отправляется на сервер.

#### Серверная часть

Поскольку для вычисления двух функций нужно 2 клиента, то возникает проблема с их обработкой. Я выбрал модуль **Select**, который дает возможность организовать неблокирующий ввод-вывод. Идея в том, что Select следит за состоянием файловых дескрипторов и при появлении возможности на чтение, запись, ... сообщает программе об этом.

В моем случае я буду отслеживать только возможность чтения из файлового дескриптора сокета, это будет означать, что на сервер пришел результат вычисления функции.

<!-- Cspell:disable -->
```py
for proc in p_list:
        proc.start() # Начинаем вычисления
        connections.append(sock.accept()[0]) # подключаем клиента для передачи данных

    for conn in connections:
        conn.setblocking(0) # необходимо для неблокирующей передачи данных


    epoll = select.epoll()

    for conn in connections:
        epoll.register(conn.fileno(), select.EPOLLIN) # Регистрируем событие возможности чтения из сокета
```
<!-- Cspell:enable -->

Далее я выставил таймер на появление меню с выбором действий:

<!-- Cspell:disable -->
```py
timer = 3 # таймер вызова меню
```
<!-- Cspell:enable -->

Вся обработка происходит в большом цикле до тех пор пока есть соединения с клиентами. Сначала мы проверяем клиентов на возможность чтения результатов

<!-- Cspell:disable -->
```py
events = epoll.poll(1) # проверка на возможность чтения из сокетов
    
    for fileno, event in events: # читаем из всех возможных сокетов
        
        data = (conn_map[fileno].recv(1024)).decode() # чтение
        logging.debug(f'Fileno {fileno} recv result {data}')
        result.append(data)
        
        # Далее убираем сокет из которого прочитали
        connections.pop(connections.index(conn_map[fileno])) 
        epoll.unregister(fileno) # убираем отслеживание сокета
        conn_map[fileno].close()
        logging.debug(f'Close fileno {fileno}')
```
<!-- Cspell:enable -->

После этого, если прошло больше `timer` времени останавливаем вычисления, выводим на экран меню и ожидаем выбора пользователя. После этого отправляем команду всем клиентам (2 клиентам, что считают функции *f*, *g*).

<!-- Cspell:disable -->
```py
if time.time()- start_time > timer and len(connections)>0 and not quest_flag: # вызов меню
    for conn in connections:    # ставим вычисления на паузу
        conn.send(str(int(Status.Pause)).encode())  
    comm = input('Write 1 to continue, 2 to stop, 3 to continue without questions: ')
    if int(comm) == Status.Cont_no_Ques:
        # если выбрана команда продолжать без вопросов, то ставим флаг и отправляем команду
        # продолжать
        quest_flag = True
        comm = str(int(Status.Cont)) 
    
    for conn in connections: # отправляем команду сокетам
        conn.send(comm.encode("utf8"))
    if int(comm) == Status.End:
        for conn in connections:
            conn.close()
        connections = []
        conn_map = {}

    start_time = time.time()
```
<!-- Cspell:enable -->

В конце, если были посчитаны обе функции, выведется результат.

#### Подстановка функций *f*, *g*

За выбор функций, что будут вычисляться отвечает этот кусок кода:

```py
# Запуск процессов, что будут считать функции
p_f = mp.Process(target=client_function, args=(pair, foo, True))
p_g = mp.Process(target=client_function, args=(pair, foo_long, False))
```
как видно это создание объектов процессов, куда передается название функции (второй аргумент в `args`) и аргумент для вычисляемой функции (аргумент в `args`).

В файле с кодом реализованы 2 тестовые функции `foo`, `foo_long`, они возвращают полученный аргумент без изменений, но `foo_long` выполняется длительное время.


***

## Лабораторная №3 "Взаимодействие потоков, критический сегмент"

Промоделировать параллельную работу двух потоков (threads) с общей ячейкой памяти:
1.  с использованием критического сегмента
2.  без использования критического сегмента
Продемонстрировать разницу. *Например, увеличивать значения общей ячейки на 1 1000 раз в каждом потоке.*

**Критическая секция**([source](https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%81%D0%B5%D0%BA%D1%86%D0%B8%D1%8F#:~:text=%D0%9A%D1%80%D0%B8%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F%20%D1%81%D0%B5%D0%BA%D1%86%D0%B8%D1%8F%20%E2%80%94%20%D1%83%D1%87%D0%B0%D1%81%D1%82%D0%BE%D0%BA%20%D0%B8%D1%81%D0%BF%D0%BE%D0%BB%D0%BD%D1%8F%D0%B5%D0%BC%D0%BE%D0%B3%D0%BE%20%D0%BA%D0%BE%D0%B4%D0%B0,%C2%BB%20(%C2%AB%D1%81%D0%BE%D1%81%D1%82%D1%8F%D0%B7%D0%B0%D0%BD%D0%B8%D1%8F%C2%BB).)) — участок исполняемого кода программы, в котором производится доступ к общему ресурсу (данным или устройству), который не должен быть одновременно использован более чем одним потоком выполнения. При нахождении в критической секции двух (или более) потоков возникает состояние «гонки» («состязания»). 

### Код программы

Сам по себе код программы простой, вот ссылка на код [link](/lab3/python/main.py). Есть глобальная переменная `CRITICAL_SEGMENT = 0` которую увеличивают определенное количество раз в каждом потоке, она моделирует критическую секцию. Вот так выглядят функции, которые выполняются в случае с критическим сегментом и без него

<!-- Cspell:disable -->
```py
def function_critical(n = 1000):
    global CRITICAL_SEGMENT
    for _ in range(n):
        CRITICAL_SEGMENT += 1

def function_non_critical(n =1000):
    a = 0

    for _ in range(n):
        a += 1
```
<!-- Cspell:enable -->

как видно, без критической секции функция просто увеличивает свою локальную переменную определенное количество раз.

### Настройка визуализации результатов

Для красивой визуализации я использовал [VizTracer](https://github.com/gaogaotiantian/viztracer/) и **Perf**. Я действовал согласно инструкции в этой [статье](https://habr.com/ru/company/mailru/blog/538706/). 

Поскольку необходимо было менять конфигурацию ядра Linux, я решил работать в виртуальной машине. Для связи с ней использовал ***ssh***, ***sftp***.

Согласно мануалу сначала нужно изменить конфигурацию ядра:

```sh
# Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing
```

Для установки **perf** использовал команду(возможно нужно будет выбрать версию для своего ядра):

```
sudo apt-get install linux-tools-generic
```

Далее я создал виртуальное окружение python ([документация](https://docs.python.org/3/library/venv.html)). Активировав его, установил нужные библиотеки

```
pip install "viztracer>=0.11.2" "per4m>=0.1,<0.2"
```

После этого я запустил простой скрипт([link](/lab3/python/script)), он состоит из команд мануала. Я не отслеживал GIL, а просто проверил активность процессов. Стоит обратить внимание, что на вход скрипту нужно подавать название файла с кодом **без окончания** `.py`.

В результате получается *html* файл. Его можно посмотреть командой

```
vizviewer result_main.html
```

### Визуализация результатов

Для начала, я запустил программу с использованием критической секции и количеством итераций `n = 1000_000`. 

![main](/lab3/python/photos/main.png)

Далее  я запустил программу без использования критической секции и количеством итераций `n = 1000_000`.

![non_critic](/lab3/python/photos/non_critic.png)

В конце я протестировал программу с критической секцией и количеством итераций `n = 1000`.

![critic 1000](/lab3/python/photos/critic_1000.png)





